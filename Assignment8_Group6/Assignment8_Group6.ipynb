{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Cleaning the Data\n",
    "\n",
    "- Remove all punctuation.\n",
    "\n",
    "- Remove all non-alphanumeric characters.\n",
    "\n",
    "- Convert all symbols to lowercase format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "\n",
    "    def __init__(word, f0):\n",
    "        token = word\n",
    "        a_count = f0\n",
    "        b_count = f0\n",
    "    \n",
    "def data_cleaner(path: str) -> str: # author Walter and Miguel\n",
    "    \n",
    "    text = \"\" # define empty text variable\n",
    "    with open(path, newline='\\n') as file: # open text file and read by line\n",
    "        temp_text = file.readlines() # store read lines in temporary string\n",
    "\n",
    "    linewordlist = [] # empty list for lines, each line in this list is also a list of words\n",
    "    for lineno, linedat in enumerate(temp_text): \n",
    "        linedat = linedat.strip('''!()-[]{};:'\"\\, <>./?@#$%^&*_~''') # take out all special trailing characters\n",
    "        linedat = linedat.lower() # convert all to lowercase\n",
    "        linewordlist.append(linedat.split())\n",
    "    for line in linewordlist: # going through each line in the file\n",
    "        for word in line: # and each word in each line\n",
    "            word = word.strip(\"\\\"!()-[]{};:', <>./?@#$%^&*_~\") # another strip pass to ensure all characters and whitespace are gone\n",
    "            word = word.replace(\"'\", \"\")\n",
    "            text += word + \"\\n\" # append word to the cleaned text string, with a newline\n",
    "    # write text data to file\n",
    "    file = open(\"cleaned.txt\", \"w\")\n",
    "    file.write(text)\n",
    "    file.close()\n",
    "\n",
    "def wordcount_dict(filepath): # author Walter\n",
    "    tokendict = {} # create new empty dictionary\n",
    "    with open(filepath) as file: # open file\n",
    "        for line in file: # iterate through all lines (words) in the file\n",
    "            line = line.strip('\\n') # remove the trailing newlines\n",
    "            if line not in tokendict: # check to create a new dictionary entry if token not already in dict\n",
    "                tokendict.update({line : 1}) # update the dictionary with the token and only 1 since we just saw it\n",
    "            elif line in tokendict: # otherwise, if it does exist\n",
    "                count = tokendict.get(line) # take the existing count\n",
    "                count += 1 # iterate by 1\n",
    "                tokendict.update({line : count}) # update in the dictionary\n",
    "    print(tokendict) # print out the dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: 2\n",
      "Path to cleaned text file: cleaned.txt\n",
      "{'trump': 9, 'responded': 2, 'to': 22, 'the': 42, 'boards': 9, 'ruling': 4, 'in': 11, 'a': 9, 'statement': 5, 'what': 1, 'facebook': 9, 'twitter': 3, 'and': 21, 'google': 1, 'have': 2, 'done': 1, 'is': 7, 'total': 2, 'disgrace': 1, 'an': 4, 'embarrassment': 1, 'our': 6, 'country': 3, 'free': 1, 'speech': 3, 'has': 1, 'been': 2, 'taken': 1, 'away': 1, 'from': 3, 'president': 3, 'of': 8, 'united': 1, 'states': 1, 'because': 1, 'radical': 1, 'left': 1, 'lunatics': 1, 'are': 4, 'afraid': 1, 'truth': 2, 'but': 1, 'will': 5, 'come': 1, 'out': 1, 'anyway': 1, 'bigger': 1, 'stronger': 1, 'than': 2, 'ever': 1, 'before': 1, 'people': 1, 'not': 3, 'stand': 1, 'for': 9, 'it': 5, 'these': 2, 'corrupt': 1, 'social': 4, 'media': 4, 'companies': 1, 'must': 8, 'pay': 1, 'political': 3, 'price': 1, 'never': 1, 'again': 2, 'be': 6, 'allowed': 2, 'destroy': 1, 'decimate': 1, 'electoral': 1, 'process': 1, 'separate': 1, 'released': 1, 'on': 7, 'wednesday': 2, 'baselessly': 1, 'claimed': 3, 'there': 3, 'was': 6, 'fraud': 1, '2020': 1, 'election': 1, 'within': 1, 'six': 1, 'months': 1, 'reexamine': 1, 'arbitrary': 1, 'penalty': 4, 'imposed': 1, 'january': 1, '7': 1, 'decide': 1, 'appropriate': 1, 'board': 5, 'said': 5, 'this': 2, 'based': 1, 'gravity': 1, 'violation': 1, 'prospect': 1, 'future': 1, 'harm': 1, 'also': 3, 'consistent': 1, 'with': 3, 'facebooks': 1, 'rules': 2, 'severe': 1, 'violations': 2, 'which': 3, 'turn': 1, 'clear': 3, 'necessary': 1, 'proportionate': 2, 'permissible': 1, 'keep': 1, 'user': 1, 'off': 1, 'platform': 1, 'undefined': 1, 'period': 1, 'no': 6, 'criteria': 1, 'when': 1, 'or': 1, 'whether': 1, 'account': 2, 'restored': 1, 'that': 9, 'gave': 1, 'trumps': 6, 'vague': 1, 'standardless': 1, 'then': 1, 'tried': 1, 'avoid': 1, 'its': 4, 'responsibilities': 1, 'by': 3, 'sending': 1, 'case': 1, 'resolve': 1, 'if': 3, 'decides': 1, 'restore': 1, 'mr': 2, 'accounts': 2, 'company': 1, 'should': 2, 'apply': 1, 'decision': 3, 'including': 1, 'any': 4, 'changes': 1, 'made': 2, 'response': 2, 'policy': 1, 'recommendations': 4, 'below': 1, 'scenario': 1, 'address': 1, 'further': 1, 'promptly': 1, 'accordance': 1, 'established': 1, 'content': 1, 'policies': 3, 'as': 1, 'part': 1, 'examination': 1, 'provide': 1, 'submitted': 1, 'american': 1, 'center': 1, 'law': 1, 'justice': 1, 'his': 4, 'behalf': 1, 'denies': 1, 'comments': 1, 'lead': 1, 'capitol': 2, 'siege': 1, 'stunningly': 1, 'call': 1, 'insurrection': 2, 'incitement': 1, 'violence': 1, 'threat': 1, 'public': 1, 'safety': 1, 'manner': 1, 'absence': 1, 'serious': 1, 'linkage': 1, 'between': 1, 'building': 1, 'incursion': 2, 'all': 2, 'genuine': 1, 'supporters': 2, 'were': 1, 'law-abiding': 1, 'certainly': 1, 'influenced': 1, 'most': 1, 'probably': 1, 'ignited': 1, 'outside': 1, 'forces': 1, 'we': 3, 'now': 1, 'consider': 1, 'determine': 1, 'action': 1, 'meantime': 1, 'remain': 1, 'suspended': 1, 'number': 1, 'how': 1, 'improve': 1, 'while': 1, 'binding': 1, 'actively': 1, 'sought': 1, 'views': 1, 'around': 1, 'figures': 1, 'carefully': 1, 'review': 1, 'critics': 1, 'reacting': 1, 'house': 1, 'minority': 1, 'leader': 1, 'kevin': 1, 'mccarthy': 1, 'tweeted': 2, 'they': 1, 'can': 2, 'ban': 4, 'conservative': 1, 'voices': 1, 'could': 1, 'next': 1, 'sen': 1, 'ted': 1, 'cruz': 2, 'r-texas': 1, 'called': 1, 'disgraceful': 1, 'every': 1, 'liberal': 1, 'celebrating': 1, 'big': 2, 'tech': 1, 'oligarchs': 1, 'muzzle': 1, 'former': 1, 'whats': 1, 'stop': 1, 'them': 1, 'silencing': 1, 'you': 1, 'rep': 1, 'adam': 1, 'schiff': 1, 'd-calif': 1, 'theres': 1, 'constitutional': 1, 'protection': 1, 'using': 1, 'incite': 1, 'willing': 1, 'do': 1, 'anything': 1, 'himself': 1, 'matter': 1, 'danger': 1, 'lies': 1, 'cost': 1, 'america': 1, 'dearly': 1, 'until': 1, 'he': 1, 'stops': 1, 'him': 1, 'say': 1, 'forever': 1, 'permanently': 1, 'banned': 1, 'jan': 1, '8': 1, 'told': 1, 'abc': 1, 'news': 1, 'recently': 1, 'written': 1, 'statements': 1, 'hes': 1, 'issuing': 1, 'during': 1, 'so': 1, 'much': 1, 'more': 1, 'elegant': 1}\n"
     ]
    }
   ],
   "source": [
    "phase = input(\"Phase: \")\n",
    "if phase == '1':\n",
    "    path = input(\"Path to data file: \")\n",
    "    text = data_cleaner(path)\n",
    "    print(text)\n",
    "if phase == '2':\n",
    "    path = input(\"Path to cleaned text file: \")\n",
    "    wordcount_dict(path)\n",
    "\n",
    "else:\n",
    "    print(F\"Sorry, phase {phase} has not yet been implemented\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
